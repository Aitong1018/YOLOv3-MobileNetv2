[net]
# Training
batch=32
subdivisions=1
width=416
height=416
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.001
burn_in=1000
max_batches = 500200
policy=steps
steps=400000,450000
scales=.1,.1

# conv1
[convolutional]
filters=32
size=3
pad=1
pre_padding=0
stride=2
batch_normalize=1
activation=relu6

# conv2_1_dwise
[convolutional]
groups=32
filters=32
size=3
stride=1
pad=1
pre_padding=0
batch_normalize=1
activation=relu6

# conv2_1_linear
[convolutional]
filters=16
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=linear

# conv2_2_expand
[convolutional]
filters=96
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv2_2_dwise
[convolutional]
groups=96
filters=96
size=3
pad=1
pre_padding=0
stride=2
batch_normalize=1
activation=relu6

# conv2_2_linear
[convolutional]
filters=24
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=linear

# conv3_1_expand
[convolutional]
filters=144
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv3_1_dwise
[convolutional]
groups=144
filters=144
size=3
stride=1
pad=1
pre_padding=0
batch_normalize=1
activation=relu6

# conv3_1_linear
[convolutional]
filters=24
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=linear

# block_3_1
[shortcut]
from=-4
activation=linear

# conv_3_2_expand
[convolutional]
filters=144
size=1
stride=1
pad=1
pre_padding=0
batch_normalize=1
activation=relu6

# conv_3_2_dwise
[convolutional]
groups=144
filters=144
size=3
pad=0
pre_padding=0
stride=2
batch_normalize=1
activation=relu6

# conv_3_2_linear
[convolutional]
filters=32
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=linear

# conv_4_1_expand
[convolutional]
filters=192
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv_4_1_dwise
[convolutional]
groups=192
filters=192
size=3
stride=1
pad=1
pre_padding=0
batch_normalize=1
activation=relu6

# conv_4_1_linear
[convolutional]
filters=32
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=linear

# block_4_1
[shortcut]
from=-4
activation=linear

# conv_4_2_expand
[convolutional]
filters=192
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv_4_2_dwise
[convolutional]
groups=192
filters=192
size=3
stride=1
pad=1
pre_padding=0
batch_normalize=1
activation=relu6

# conv_4_2_linear
[convolutional]
filters=32
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=linear

# block_4_2
[shortcut]
from=-4
activation=linear

# conv_4_3_expand
[convolutional]
filters=192
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv_4_3_dwise
[convolutional]
groups=192
filters=192
size=3
stride=2
pad=1
pre_padding=0
batch_normalize=1
activation=relu6

# conv_4_3_linear
[convolutional]
filters=64
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=linear

# conv_4_4_expand
[convolutional]
filters=384
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv_4_4_dwise
[convolutional]
groups=384
filters=384
size=3
stride=1
pad=1
pre_padding=0
batch_normalize=1
activation=relu6

# conv_4_4_linear
[convolutional]
filters=64
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=linear

# block_4_4
[shortcut]
from=-4
activation=linear

# conv_4_5_expand
[convolutional]
filters=384
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv_4_5_dwise
[convolutional]
groups=384
filters=384
size=3
stride=1
pad=1
pre_padding=0
batch_normalize=1
activation=relu6

# conv_4_5_linear
[convolutional]
filters=64
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=linear

# block_4_5
[shortcut]
from=-4
activation=linear

# conv_4_6_expand
[convolutional]
filters=384
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv_4_6_dwise
[convolutional]
groups=384
filters=384
size=3
stride=1
pad=1
pre_padding=0
batch_normalize=1
activation=relu6

# conv_4_6_linear
[convolutional]
filters=64
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=linear

# block_4_6
[shortcut]
from=-4
activation=linear

# conv_4_7_expand
[convolutional]
filters=384
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv_4_7_dwise
[convolutional]
groups=384
filters=384
size=3
pad=1
pre_padding=0
stride=1
batch_normalize=1
activation=relu6

# conv_4_7_linear
[convolutional]
filters=96
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=linear

# conv_5_1_expand
[convolutional]
filters=576
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv_5_1_dwise
[convolutional]
groups=576
filters=576
size=3
stride=1
pad=1
pre_padding=0
batch_normalize=1
activation=relu6

# conv_5_1_linear
[convolutional]
filters=96
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=linear

# block_5_1
[shortcut]
from=-4
activation=linear

# conv_5_2_expand
[convolutional]
filters=576
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv_5_2_dwise
[convolutional]
groups=576
filters=576
size=3
stride=1
pad=1
pre_padding=0
batch_normalize=1
activation=relu6

# conv_5_2_linear
[convolutional]
filters=96
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=linear

# block_5_2
[shortcut]
from=-4
activation=linear

# conv_5_3_expand
[convolutional]
filters=576
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv_5_3_dwise
[convolutional]
groups=576
filters=576
size=3
pad=1
pre_padding=0
stride=2
batch_normalize=1
activation=relu6

# conv_5_3_linear
[convolutional]
filters=160
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=linear

# conv_6_1_expand
[convolutional]
filters=960
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv_6_1_dwise
[convolutional]
groups=960
filters=960
size=3
stride=1
pad=1
pre_padding=0
batch_normalize=1
activation=relu6

# conv_6_1_linear
[convolutional]
filters=160
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=linear

# block_6_1
[shortcut]
from=-4
activation=linear

# conv_6_2_expand
[convolutional]
filters=960
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv_6_2_dwise
[convolutional]
groups=960
filters=960
size=3
stride=1
pad=1
pre_padding=0
batch_normalize=1
activation=relu6

# conv_6_2_linear
[convolutional]
filters=160
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=linear

# block_6_2
[shortcut]
from=-4
activation=linear

# conv_6_3_expand
[convolutional]
filters=960
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv_6_3_dwise
[convolutional]
groups=960
filters=960
size=3
stride=1
pad=1
pre_padding=0
batch_normalize=1
activation=relu6

# conv_6_3_linear
[convolutional]
filters=320
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=linear

# conv_6_4
[convolutional]
filters=1280
size=1
stride=1
pad=1
pre_padding=0
batch_normalize=1
activation=relu6

######################

# conv0
[convolutional]
filters=512
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv1_dwise
[convolutional]
groups=512
filters=512
size=3
stride=1
pad=1
pre_padding=0
batch_normalize=1
activation=relu6

# conv3
[convolutional]
filters=1024
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv4
[convolutional]
filters=512
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv5_dwise
[convolutional]
groups=512
filters=512
size=3
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv6
[convolutional]
filters=1024
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv7
[convolutional]
filters=512
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv8_dwise
[convolutional]
groups=512
filters=512
size=3
stride=1
pad=1
pre_padding=0
batch_normalize=1
activation=relu6

# conv9
[convolutional]
filters=1024
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv10 --> conv_l
[convolutional]
filters=75
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=0
activation=linear

[yolo]
mask = 6,7,8
anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326
classes=20
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1

[route]
layers = -5

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=0
pre_padding=0
activation=relu6

[upsample]
stride=2

[route]
layers = -1, 46

# conv11
[convolutional]
filters=256
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv12_dwise
[convolutional]
groups=256
filters=256
size=3
stride=1
pad=1
pre_padding=0
batch_normalize=1
activation=relu6

# conv13
[convolutional]
filters=512
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv14
[convolutional]
filters=256
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv15_dwise
[convolutional]
groups=256
filters=256
size=3
stride=1
pad=1
pre_padding=0
batch_normalize=1
activation=relu6

# conv16
[convolutional]
filters=512
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv17
[convolutional]
filters=256
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv18_dwise
[convolutional]
groups=256
filters=256
size=3
stride=1
pad=1
pre_padding=0
batch_normalize=1
activation=relu6

# conv19
[convolutional]
filters=512
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv20
[convolutional]
filters=75
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=0
activation=linear

[yolo]
mask = 3,4,5
anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326
classes=20
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1

[route]
layers = -5

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=0
pre_padding=0
activation=relu6

[upsample]
stride=2

[route]
layers = -1, 20

# conv21
[convolutional]
filters=128
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv22_dwise
[convolutional]
groups=128
filters=128
size=3
stride=1
pad=1
pre_padding=0
batch_normalize=1
activation=relu6

# conv23
[convolutional]
filters=256
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv24
[convolutional]
filters=128
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv25_dwise
[convolutional]
groups=128
filters=128
size=3
stride=1
pad=1
pre_padding=0
batch_normalize=1
activation=relu6

# conv26
[convolutional]
filters=256
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv27
[convolutional]
filters=128
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv28_dwise
[convolutional]
groups=128
filters=128
size=3
stride=1
pad=1
pre_padding=0
batch_normalize=1
activation=relu6

# conv29
[convolutional]
filters=256
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=1
activation=relu6

# conv30
[convolutional]
filters=75
size=1
stride=1
pad=0
pre_padding=0
batch_normalize=0
activation=linear

[yolo]
mask = 0,1,2
anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326
classes=20
num=9
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1